# Single node deployment with GPU
# Example: helm install sglang ./helm-charts/sglang -f ./helm-charts/sglang/examples/single-node.yaml

deploymentMode: "single"

global:
  image:
    repository: lmsysorg/sglang
    tag: latest
    pullPolicy: Always
  
  model:
    path: "meta-llama/Llama-3.1-8B-Instruct"
    trustRemoteCode: true
    
  huggingface:
    token: ""  # Set your HuggingFace token here if needed
    
  resources:
    gpu: 1
    memory: "16Gi"

single:
  enabled: true
  replicaCount: 1
  
  service:
    type: LoadBalancer
    port: 30000
    targetPort: 30000
    
  server:
    host: "0.0.0.0"
    port: 30000
    enableMetrics: true
    metricsPort: 8080
    
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
      port: 30000
    initialDelaySeconds: 60
    periodSeconds: 30
    
  readinessProbe:
    enabled: true
    httpGet:
      path: /health
      port: 30000
    initialDelaySeconds: 30
    periodSeconds: 10

storage:
  shm:
    enabled: true
    size: "16Gi"
    
  model:
    type: "huggingface"  # Use HuggingFace model directly
    
  huggingfaceCache:
    enabled: true
    hostPath: "/root/.cache/huggingface"

runtimeClass:
  enabled: true
  name: "nvidia"

serviceAccount:
  create: true
